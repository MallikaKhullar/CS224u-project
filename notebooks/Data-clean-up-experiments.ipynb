{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.7\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt #only if you want to analyze the date created feature\n",
    "import json \n",
    "from types import SimpleNamespace\n",
    "import sys\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "# !pip install textblob\n",
    "from textblob import TextBlob\n",
    "# !pip install tabulate\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the CSV files.\n",
    "1. Mental, Anxiety and Unrelated are all posted by ANXIOUS users\n",
    "2. Control posts are posted by CONTROL users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anx_1 = pd.read_csv(\"dataset/reddit-posts-mental.csv\", index_col=0)\n",
    "df_anx_2 = pd.read_csv(\"dataset/reddit-posts-anxiety.csv\", index_col=0)\n",
    "df_anx_3 = pd.read_csv(\"dataset/reddit-posts-unrelated.csv\", index_col=0)\n",
    "df_anxiety_group = pd.concat([df_anx_1, df_anx_2, df_anx_3])\n",
    "df_control_group = pd.read_csv(\"dataset/reddit-control.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the function to tokenize a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(string, to_lower): # TODO : Change to BERT / explore more as we see fit\n",
    "    ''' String ---> Tokenize ---> Lowercase (if set to true) '''\n",
    "    try:\n",
    "        return TreebankWordTokenizer().tokenize(string) if to_lower is False else \\\n",
    "            [token.lower() for token in TreebankWordTokenizer().tokenize(string)]\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the title and body and add it to the feature dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_control_group['f-title-tokens'] = [get_tokens(title, True) for title in df_control_group['title']]\n",
    "print(\"Done\")\n",
    "df_control_group['f-body-tokens'] = [get_tokens(body, True) for body in df_control_group['body']]\n",
    "print(\"Done\")\n",
    "df_anxiety_group['f-title-tokens'] = [get_tokens(title, True) for title in df_anxiety_group['title']]\n",
    "print(\"Done\")\n",
    "df_anxiety_group['f-body-tokens'] = [get_tokens(body, True) for body in df_anxiety_group['body']]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SENTIMENT ANALYSIS:\n",
    "https://textblob.readthedocs.io/en/dev/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polarity(string): \n",
    "    '''  '''\n",
    "    try:\n",
    "        tb = TextBlob(string)\n",
    "        return tb.sentiment.polarity # TODO : CHANGE THIS AS PER NEED\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "df_control_group['f-title-sentiment'] = [get_polarity(title) for title in df_control_group['title']]\n",
    "print(\"Done\")\n",
    "df_control_group['f-body-sentiment'] = [get_polarity(body)  for body in df_control_group['body']]\n",
    "print(\"Done\")\n",
    "df_anxiety_group['f-title-sentiment'] = [get_polarity(title)  for title in df_anxiety_group['title']]\n",
    "print(\"Done\")\n",
    "df_anxiety_group['f-body-sentiment'] = [get_polarity(body)  for body in df_anxiety_group['body']]\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_control_group.head(10).to_html('temp.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
